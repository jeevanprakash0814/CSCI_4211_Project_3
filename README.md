# Henry Roycroft, Jeevan Prakash, and Kailash Kalyanasundaram, Zhang CSCI4211, 16/12/2021
 
## Ethernet-Algorithm
We implemented a **nested dictionary data structure** to simulate switch flow tables. The nested dictionary is used to keep track of all the switches on the network and their flow tables, where each switch is a key in the dictionary. Each key, or switch, then has a nested dictionary corresponding to it, simulating a switch flow table. Each nested dictionary contains MAC addresses and a corresponding port number for each switch. Initially, using the ``handle_PacketIn()`` function we flood the network so that all switch flow tables are saved before any commands are run on the network. Using the ``handle_PacketIn()`` function, we forward the packets to the desired destinations based on our nested dictionary/switch flow table. Then commands, such as **ping** and **iperf**, can be run on the network to evaluate *latency* and *throughput* on the topology as all the switch flow tables will already be completed.
 
## Pseudocode
For our pseudocode, we added the ``_handle_ConnectionUp()``, ``flood()`` and ``drop()`` functions, and modified the ``_handle_PacketIn()`` and ``launch()`` function. The ``launch()`` function was modified to include a call to ``_handle_ConnectionUp()``.  This call happens at set-up, and the ``_handle_ConnectionUp()`` function operates by having every switch on the network flood the network to determine which hosts connect to which port numbers.  Having the network flooded at setup allows for all the switch flow tables to be completed before any commands are given to the network.  Thus, when a **ping** or **iperf** command is run on the network, the switch flow tables  will already be completed, and the **RTT** will be the minimum expected time.

The bulk of the work done in **ethernet-learning.py** is completed in ``_handle_PacketIn()``.  This function is activated when a packet is received from a switch, and this function uses the nested dictionary to forward the packets to the desired destination.  First the function checks to see if the nested dictionary already has an entry for the switch that has received the packet.  If the nested dictionary doesn’t already contain an entry, the dictionary is updated to include this switch as a key and an empty dictionary is its associated value.  The nested dictionary associated with the switch is then updated to make sure it includes an entry for the packet just received, where the **source MAC address** is the key and the **port the packet came in** is the value.  The function then checks to see if the packet is *multicast* or if the switch does not have an entry in the associated nested dictionary, and floods the network if that is the case in order to determine which port to forward the packet out of. The function then checks if the destination address indicates that the packet should be forwarded to the same port it came in on.  If this is the case, a call to ``drop()`` is made and the packet is dropped. Additionally, any future packets that have the same condition will also be dropped.  Otherwise, the simulated switch flow table uses an entry already in the switch’s switch table (nested dictionary) to find the desired output port. A new *flow message* is then created with the port number the packet is to be forwarded to, this message is then sent to the switch where the desired action is carried out.
 
> The ``flood()`` function operates by flooding all the ports of the switch, except the one the packet came in on, with packets to determine where the destination of the packet is located.

>The ``drop()`` function operates by dropping the packet that has the same **source and destination MAC addresses**.
 
 
## Comments/assumption section
When using the ``_handle_Connection_Up`` handler we created, all the switches are flooded at the initiation of the controller. This allows all the switches to learn in advance about the *MAC addresses* that are located at all of their respective ports. Using the custom-made **Connection_Up handler** allows us to immediately perform **ping** and **iperf** commands without any **flooding delays** that are needed for *self-learning*. Due to the use of this initial flood, we do not need to handle any packet in messages since this network is *static* and now every switch knows how to handle every packet. *Static* means that the *topology* does not change while we are running it in mininet.
 
However, if we were to not include the ``_handle_Connection_Up`` handling that we did, the **self-learning algorithm** we created still works flawlessly. The first time pinging across switches leads to some delays **since the switches need to learn**. This delay shows up in the first couple *ICMP ping packets* that are sent across the switch. These first couple pings will have a much higher latency, which indicates that flooding is occurring to help the switches learn. After this however, the next pings all produce **nominal latency values**. This can be tested if the line ``core.openflow.addListenerByName("ConnectionUp", _handle_Connection_Up)`` is commented out and the **ethernet-learning.py** is rerun. After the POX is up, run ``h1 ping h3`` with **topology-a.py**, and you will see the first two pings having a much higher value than the rest of the pings, which will all reach a nominal value around ``80 ms``. Similar behavior is observed with the **iperf** command.